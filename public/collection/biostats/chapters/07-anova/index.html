<!DOCTYPE html>
<html lang="en" dir="ltr"><head>
  
                           
     


<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.96.0" />
<title>6. Analysis of Variance (ANOVA) | BCB R Stats Pages</title>


<meta property="twitter:site" content="@ajsmit">
<meta property="twitter:creator" content="@ajsmit">







  
    
  
<meta name="description" content="What you need to know upfront.">


<meta property="og:site_name" content="BCB R Stats Pages">
<meta property="og:title" content="6. Analysis of Variance (ANOVA) | BCB R Stats Pages">
<meta property="og:description" content="What you need to know upfront." />
<meta property="og:type" content="page" />
<meta property="og:url" content="/collection/biostats/chapters/07-anova/" />
<meta property="og:locale" content="en">




    
        <meta property="og:image" content="/img/papillons.jpg" >
        <meta property="twitter:card" content="summary_large_image">
        <meta name="twitter:image" content="/img/papillons.jpg" >
    
  <meta itemprop="name" content="6. Analysis of Variance (ANOVA)">
<meta itemprop="description" content="“He uses statistics as a drunken man uses lamp posts—for support rather than for illumination.”
— Marissa Mayer
 Whole big books have been written about Analysis of Variance (ANOVA). Although there are many ANOVA experimental designs available, biologists are taught to pay special attention to the design of experiments, and generally make sure that the experiments are fully factorial (in the case of two-way or higher ANOVAs) and balanced."><meta itemprop="datePublished" content="2021-01-01T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-01-01T00:00:00+00:00" />
<meta itemprop="wordCount" content="4469">
<meta itemprop="keywords" content="" />
  
  
  <!--[if IE]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/img/favicon.ico" type="image/x-icon">
  
  
  <link rel="stylesheet" href="/style.main.min.13dd27d3efb7ed4ad82be3040182ddbf5ab9d3b4d6d01f0ba3930845932fce66.css" integrity="sha256-E90n0&#43;&#43;37UrYK&#43;MEAYLdv1q507TW0B8Lo5MIRZMvzmY=" media="screen">
  
  
  <script src="/panelset.min.8f4cba0107356728f266d94a12a4d18ef504eda8a9a284cda73675bae7884a68.js" type="text/javascript"></script>
  
  
  <script src="/main.min.318ee9c0652bba0149e7503c97e37e638937f3a9cad9233e6d0ba00bf7a46a5e.js" type="text/javascript"></script>
</head>
<body>
      <div class="grid-container single-series">
<header class="site-header pt4 pb2 mb4 bb b--transparent ph5 headroom z-max" role="banner">
  <nav class="site-nav db dt-l w-100" role="navigation">
    <a class="site-brand db dtc-l v-mid link no-underline w-100 w-33-l tc tl-l" href="/" title="Home">
      <img src="/img/xaringan-outline.png" class="dib db-l h2 w-auto" alt="BCB R Stats Pages">
    </a>
    <div class="site-links db dtc-l v-mid w-100 w-47-l tc tr-l mt3 mt0-l ttu tracked">
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/about/" title="About AJ Smit">About</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/workshops/" title="BCB Hons">BCB Hons</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 " href="/project/" title="Project Portfolio">Projects</a>
      
        
        
        
      <a class="link f6 f5-l dib pv1 ph2 active" href="/collection/" title="R Courses">R Courses</a>
      
      
    </div>
  </nav>
</header>


<main class="page-main ph4 pt4" role="main">
  <section class="page-content mw7 center">
    <article class="post-content pa0 pr3-l">
      <header class="post-header">
        <h4 class="breadcrumb pb5">

  
    
      
  
    
      
  
    
      
  

    
    
      <a href="/collection/">B.Sc. (Hons.) R modules</a>
    
  

    
    
      <a href="/collection/biostats/">BCB744 (Biostats)</a>
    
  

    
    
      6. Analysis of Variance (ANOVA)
    
  

</h4>




        
        <h1 class="f1 lh-solid measure-narrow mb3 fw4">6. Analysis of Variance (ANOVA)</h1>
        
        <p class="f6 measure lh-copy mv1"></p>
        <p class="f7 db mv0 ttu">January 1, 2021</p>
        
        
      
      <div class="ph0 pt5">
        
    
    
    
    
    
    
    
      
      
  <a class="btn-links mr2 ba dib" href="https://ajsmit.github.io/BCB744/ANOVA_exercises.html" target="_blank" rel="noopener"><i class="fa fa-star fa-lg fa-fw mr2"></i>ANOVA Exercises</a>


      </div>
      
        
      </header>
      <section class="post-body pt5 pb4">
        


<!--- # ANOVA --->
<blockquote>
<p><em>“He uses statistics as a drunken man uses lamp posts—for support rather than for illumination.”</em></p>
<p>— Marissa Mayer</p>
</blockquote>
<p>Whole big books have been written about Analysis of Variance (ANOVA). Although there are many ANOVA experimental designs available, biologists are taught to pay special attention to the design of experiments, and generally make sure that the experiments are fully factorial (in the case of two-way or higher ANOVAs) and balanced. For this reason we will focus in this Introductory Statistics course on one-way and factorial ANOVAs only.</p>
<p>As <a href="https://ajsmit.github.io/R_Stats_Official/06-t_tests.html"><em>t</em>-tests</a>, ANOVAs require that some assumptions are met:</p>
<ul>
<li>Normally distributed data</li>
<li>Homogeneity of variances</li>
<li>Independence of data</li>
<li>In our case, we will encourage also that the data are balanced</li>
</ul>
<p>If some of the above assumptions are violated, then your course of action is either to transform the data (if non-normal) or to use a generalised linear model (also when non-normal), or to use a linear mixed model (when the assumption on non-independence cannot be guaranteed). We will get to some of these methods in later chapters. Linked to the above, ANOVAs are also sensitive to the presence of outliers (see our earlier discussion about the mean and how it differs from the median), so we need to ensure that outliers are not present (they can be removed, and there are many ways of finding them and eliminating them). If outliers are an important feature of the data, then a non-parametric test can be used, or some other test that works well with extreme values can be applied.</p>
<p>Rather than talking about <em>t</em>-tests and ANOVAs as separate things, let us acknowledge that they are similar ways of asking the same question. That question being, are the means of these two or more things we want to compare different, or the same? At this stage it is important to note that the independent variable is categorical (i.e. a factor denoting two or more different treatments or sampling conditions) and that the dependent variable is continuous. You may perhaps be more familiar with this question when it is presented as a set of hypotheses.</p>
<blockquote>
<p>H0: Group A is not different from group B.</p>
<p>H1: Group A is different from group B.</p>
</blockquote>
<p>This is a scientific question in the simplest sense. Often, for basic inquiries such as that posed above, we need to see if one group differs significantly from another. The way in which we accomplish this is by looking at the mean and variance within a set of data compared against another similar set. In order to do so appropriately however we need to first assume that both sets of data are normally distributed, and that the variance found within each set of data is similar. These are the two primary assumptions we learned about in the Chapter on <a href="https://ajsmit.github.io/R_Stats_Official/06-t_tests.html"><em>t</em>-tests</a>, and if they are met then we may use parametric tests. We will learn in the Chapter on <a href="https://ajsmit.github.io/R_Stats_Official/11-transformations.html">Transformations</a> what we can do if these assumptions are not meant and we cannot adequately transform our data, meaning we will need to use non-parametric tests.</p>
<div id="remember-the-t-test" class="section level2">
<h2>Remember the <em>t</em>-test</h2>
<p>As you know, a <em>t</em>-test is used when we want to compare two different sample sets against one another. This is also known as a two-factor or two level test. When one wants to compare multiple (more than two) sample sets against one another an ANOVA is required (see below). Remember how to perform a <em>t</em>-test in R: we will revisit this test using the <code>chicks</code> data, but only for Diets 1 and 2 from day 21.</p>
<pre class="r"><code># First grab the data
chicks &lt;- as_tibble(ChickWeight)

# Then subset out only the sample sets to be compared
chicks_sub &lt;- chicks %&gt;% 
  filter(Diet %in% c(1, 2), Time == 21)</code></pre>
<p>Once we have filtered our data we may now perform the <em>t</em>-test. Traditionally this would be performed with <code>t.test()</code>, but recent developments in R have made any testing for the comparison of means more convenient by wrapping everything up into the one single function <code>compare_means()</code>. We may use only this one single function for many of the tests we will perform in this chapter as well as the Chapter on <a href="https://ajsmit.github.io/R_Stats_Official/06-t_tests.html"><em>t</em>-tests</a>. To use <code>compare_means()</code> for a <em>t</em>-test we must simply specify this in the <code>method</code> argument, as seen below:</p>
<pre class="r"><code>compare_means(weight ~ Diet, data = chicks_sub, method = &quot;t.test&quot;)</code></pre>
<pre><code>R&gt; # A tibble: 1 × 8
R&gt;   .y.    group1 group2     p p.adj p.format p.signif method
R&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; 
R&gt; 1 weight 1      2      0.218  0.22 0.22     ns       T-test</code></pre>
<p>Unfortunately, the means are not provided as part of the outcome, but fret not! The means are:</p>
<pre class="r"><code>chicks_sub %&gt;% 
  group_by(Diet) %&gt;% 
  summarise(mean_mass = mean(weight))</code></pre>
<pre><code>R&gt; # A tibble: 2 × 2
R&gt;   Diet  mean_mass
R&gt;   &lt;fct&gt;     &lt;dbl&gt;
R&gt; 1 1          178.
R&gt; 2 2          215.</code></pre>
<p>Contrast the output with that of the atandard <em>t</em>-test function, <code>t.test()</code>:</p>
<pre class="r"><code>t.test(weight ~ Diet, data = chicks_sub)</code></pre>
<pre><code>R&gt; 
R&gt;  Welch Two Sample t-test
R&gt; 
R&gt; data:  weight by Diet
R&gt; t = -1.2857, df = 15.325, p-value = 0.2176
R&gt; alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0
R&gt; 95 percent confidence interval:
R&gt;  -98.09263  24.19263
R&gt; sample estimates:
R&gt; mean in group 1 mean in group 2 
R&gt;          177.75          214.70</code></pre>
<p>The choice of whether to use <code>compare_means()</code> or <code>t.test()</code> is yours.</p>
<blockquote>
<p><strong>Note:</strong> If you do decide to use the <code>compare_means()</code> function, please make sure that you know exactly which test is being used! This is, <em>t</em>-test for two means, or ANOVA for more than two means. In your Methods and Results you will want to report the name of the test being used internally within <code>compare_means()</code>, i.e. <code>t.test()</code> or <code>aov()</code>. Do NOT say you used the <code>compare_means()</code> function – rather, know what it does!</p>
</blockquote>
<p>As one may recall from the previous chapter, whenever we want to give a formula to a function in R, we use the <code>~</code>. The formula used above, <code>weight ~ Diet</code>, reads in plain English as “weight as a function of diet”. This is perhaps easier to understand as “Y as a function of X”. This means that we are assuming whatever is to the left of the <code>~</code> is the dependant variable, and whatever is to the right is the independent variable. We then tell <code>compare_means()</code> to run a <em>t</em>-test on our <code>chicks_sub</code> dataframe and it does the rest. We see in the output above that this function gives us a rather tidy read-out of the information we require to test a potential hypothesis. Let’s take a moment to look through the help file for this function and see what all of this means. Did the Diet 1 and 2 produce significantly fatter birds?</p>
<p>One could also supplement the output by producing a graph:</p>
<pre class="r"><code>library(ggstatsplot)

## since the confidence intervals for the effect sizes are computed using
## bootstrapping, important to set a seed for reproducibility
set.seed(13)

## parametric t-test and box plot
p1 &lt;- ggbetweenstats(
  data = chicks_sub,
  x = Diet,
  y = weight,
  xlab = &quot;Diet&quot;,
  ylab = &quot;Chick mass (g)&quot;,
  plot.type = &quot;box&quot;,
  type = &quot;p&quot;,
  results.subtitle = FALSE,
  conf.level = 0.95,
  title = &quot;t-test&quot;,
  package = &quot;ggsci&quot;,
  palette = &quot;nrc_npg&quot;
)
p1</code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/unnamed-chunk-6-1.png" width="70%" /></p>
<p>Notice above that we did not need to specify to use a <em>t</em>-test. The <code>ggbetweenstats()</code> function automatically determines if an independent samples <em>t</em>-test or a 1-way ANOVA is required based on whether there are two groups or three or more groups within the grouping (factor) variable.</p>
</div>
<div id="anova" class="section level2">
<h2>ANOVA</h2>
<p>In the <code>chicks</code> data we have four diets, not only two as in the <em>t</em>-test example just performed. Why not then simply do a <em>t</em>-test multiple times, once for each pair of diets given to the chickens? The problem is that the chances of committing a Type I error increases as more multiple comparisons are done. So, the overall chance of rejecting the null hypothesis increases. Why? If one sets <span class="math inline">\(\alpha=0.05\)</span> (the significance level below which the null hypothesis is no longer accepted), one will still reject the null hypothesis 5% of the time when it is in fact true (i.e. when there is no difference between the groups). When many pairwise comparisons are made, the probability of rejecting the null hypothesis at least once is higher because we take this 5% risk each time we repeat a <em>t</em>-test. In the case of the chicken diets, we would have to perform six <em>t</em>-tests, and the error rate would increase to slightly less than <span class="math inline">\(6\times5\%\)</span>. If you insist in creating more work for yourself and do <em>t</em>-tests many times, one way to overcome the problem of committing Type I errors that stems from multiple comparisons is to apply a Bonferroni correction.</p>
<p>Or better still, we do an ANOVA that controls for these Type I errors so that it remains at 5%.</p>
<p>A suitable null hypothesis for our chicken weight data is:</p>
<p><span class="math display">\[H_{0}:\mu_{1}=\mu_{2}=\mu_{3}=\mu_{4}\]</span> where <span class="math inline">\(\mu_{1...4}\)</span> are the means of the four diets.</p>
<p>At this point I was very tempted to put many equations here, but I ommitted them for your sake. Let us turn to some examples.</p>
<div id="single-factor" class="section level3">
<h3>Single factor</h3>
<p>We continue with the chicken data. The <em>t</em>-test showed that Diets 1 and 2 resulted in the same chicken masses at the end of the experiment at Day 21. What about the other two diets? Our null hypothesis is that, at Day 21, <span class="math inline">\(\mu_{1}=\mu_{2}=\mu_{3}=\mu_{4}\)</span>. Is there a statistical difference between chickens fed these four diets, or do we retain the null hypothesis? The R function for an ANOVA is <code>aov()</code>. To look for significant differences between all four diets on the last day of sampling we use this one line of code:</p>
<pre class="r"><code>chicks.aov1 &lt;- aov(weight ~ Diet, data = filter(chicks, Time == 21))
summary(chicks.aov1)</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
R&gt; Diet         3  57164   19055   4.655 0.00686 **
R&gt; Residuals   41 167839    4094                   
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p><strong>Task 1:</strong> What does the outcome say about the chicken masses? Which ones are different from each other?</p>
</blockquote>
<blockquote>
<p><strong>Task 2:</strong> Devise a graphical display of this outcome.</p>
</blockquote>
<p>If this seems too easy to be true, it’s because we aren’t quite done yet. You could use your graphical display to eyeball where the significant differences are, or we can turn to a more ‘precise’ approach. The next step one could take is to run a Tukey HSD test on the results of the ANOVA by wrapping <code>tukeyHSD()</code> around <code>aov()</code>:</p>
<pre class="r"><code>TukeyHSD(chicks.aov1)</code></pre>
<pre><code>R&gt;   Tukey multiple comparisons of means
R&gt;     95% family-wise confidence level
R&gt; 
R&gt; Fit: aov(formula = weight ~ Diet, data = filter(chicks, Time == 21))
R&gt; 
R&gt; $Diet
R&gt;          diff        lwr       upr     p adj
R&gt; 2-1  36.95000  -32.11064 106.01064 0.4868095
R&gt; 3-1  92.55000   23.48936 161.61064 0.0046959
R&gt; 4-1  60.80556  -10.57710 132.18821 0.1192661
R&gt; 3-2  55.60000  -21.01591 132.21591 0.2263918
R&gt; 4-2  23.85556  -54.85981 102.57092 0.8486781
R&gt; 4-3 -31.74444 -110.45981  46.97092 0.7036249</code></pre>
<p>The output of <code>tukeyHSD()</code> shows us that pairwise comparisons of all of the groups we are comparing.</p>
<p>We may also produce a graphical summary:</p>
<pre class="r"><code>set.seed(666)

## parametric t-test and box plot
p2 &lt;- ggbetweenstats(
  data = filter(chicks, Time == 21),
  x = Diet,
  y = weight,
  xlab = &quot;Diet&quot;,
  ylab = &quot;Chick mass (g)&quot;,
  plot.type = &quot;box&quot;,
  type = &quot;parametric&quot;,
  results.subtitle = TRUE,
  pairwise.comparisons = TRUE,
  pairwise.display = &quot;non-significant&quot;,
  conf.level = 0.95,
  title = &quot;ANOVA&quot;,
  package = &quot;ggsci&quot;,
  palette = &quot;nrc_npg&quot;
)
p2</code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/unnamed-chunk-9-1.png" width="70%" /></p>
<blockquote>
<p><strong>Task 3:</strong> Look at the help file for this function to better understand what the output means.</p>
</blockquote>
<blockquote>
<p><strong>Task 4:</strong> How does one interpret the results? What does this tell us about the effect that that different diets has on the chicken weights at Day 21?</p>
</blockquote>
<blockquote>
<p><strong>Task 5:</strong> Figure out a way to plot the Tukey HSD outcomes.</p>
</blockquote>
<blockquote>
<p><strong>Task 6:</strong> Why does the ANOVA return a significant result, but the Tukey test shows that not all of the groups are significantly different from one another?</p>
</blockquote>
<blockquote>
<p><strong>Task 7:</strong> Produce a graphical display of the Tukey HSD result.</p>
</blockquote>
<!-- ```{r} -->
<!-- # plot(TukeyHSD(chicks.aov)) -->
<!-- ``` -->
<p>Now that we’ve seen how to perform a single factor ANOVA, let’s watch some animations that highlight how certain aspects of our data may affect our results.</p>
<p><strong>When the sample size changes:</strong></p>
<div class="figure">
<video src="/collection/biostats/chapters/07-anova_files/aov_n_slide.mp4" style="width:70.0%" controls=""><a href="/collection/biostats/chapters/07-anova_files/aov_n_slide.mp4"></a></video>
<p class="caption">Changing sample size</p>
</div>
<p><strong>When the mean of a sample changes:</strong></p>
<div class="figure">
<video src="/collection/biostats/chapters/07-anova_files/aov_mean_slide.mp4" style="width:70.0%" controls=""><a href="/collection/biostats/chapters/07-anova_files/aov_mean_slide.mp4"></a></video>
<p class="caption">Changing means</p>
</div>
<p><strong>When the variance of a sample changes:</strong></p>
<div class="figure">
<video src="/collection/biostats/chapters/07-anova_files/aov_sd_slide.mp4" style="width:70.0%" controls=""><a href="/collection/biostats/chapters/07-anova_files/aov_sd_slide.mp4"></a></video>
<p class="caption">Changing variance</p>
</div>
</div>
<div id="multiple-factors" class="section level3">
<h3>Multiple factors</h3>
<p>What if we have multiple grouping variables, and not just one? In the case of the chicken data, there is also time that seems to be having an effect.</p>
<blockquote>
<p><strong>Task 8:</strong> How is time having an effect?</p>
</blockquote>
<blockquote>
<p><strong>Task 9:</strong> What hypotheses can we construct around time?</p>
</blockquote>
<p>Let us look at some variations around questions concerning time. We might ask, at a particular time step, are there differences amongst the effect due to diet on chicken mass? Let’s see when diets are starting the have an effect by examining the outcomes at times 0, 2, 10, and 21:</p>
<pre class="r"><code>summary(aov(weight ~ Diet, data = filter(chicks, Time %in% c(0))))</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value Pr(&gt;F)
R&gt; Diet         3   4.32   1.440   1.132  0.346
R&gt; Residuals   46  58.50   1.272</code></pre>
<pre class="r"><code>summary(aov(weight ~ Diet, data = filter(chicks, Time %in% c(2))))</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
R&gt; Diet         3  158.4   52.81   4.781 0.00555 **
R&gt; Residuals   46  508.2   11.05                   
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(aov(weight ~ Diet, data = filter(chicks, Time %in% c(10))))</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
R&gt; Diet         3   8314    2771    6.46 0.000989 ***
R&gt; Residuals   45  19304     429                     
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(aov(weight ~ Diet, data = filter(chicks, Time %in% c(21))))</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value  Pr(&gt;F)   
R&gt; Diet         3  57164   19055   4.655 0.00686 **
R&gt; Residuals   41 167839    4094                   
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p><strong>Task 10:</strong> What do you conclude from the above series of ANOVAs?</p>
</blockquote>
<blockquote>
<p><strong>Task 11:</strong> What problem is associated with running multiple tests in the way that we have done here?</p>
</blockquote>
<p>Or we may ask, regardless of diet (i.e. disregarding the effect of diet by clumping all chickens together), is time having an effect?</p>
<pre class="r"><code>chicks.aov2 &lt;- aov(weight ~ as.factor(Time), data = filter(chicks, Time %in% c(0, 2, 10, 21)))
summary(chicks.aov2)</code></pre>
<pre><code>R&gt;                  Df Sum Sq Mean Sq F value Pr(&gt;F)    
R&gt; as.factor(Time)   3 939259  313086   234.8 &lt;2e-16 ***
R&gt; Residuals       190 253352    1333                   
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p><strong>Task 12:</strong> What do you conclude from the above ANOVA?</p>
</blockquote>
<p>Or, to save ourselves a lot of time and reduce the coding effort, we may simply run a two-way ANOVA and look at the effects of <code>Diet</code> and <code>Time</code> simultaneously. To specify the different factors we put them in our formula and separate them with a <code>+</code>:</p>
<pre class="r"><code>summary(aov(weight ~ Diet + as.factor(Time), data = filter(chicks, Time %in% c(0, 21))))</code></pre>
<pre><code>R&gt;                 Df Sum Sq Mean Sq F value  Pr(&gt;F)    
R&gt; Diet             3  39595   13198   5.987 0.00091 ***
R&gt; as.factor(Time)  1 734353  734353 333.120 &lt; 2e-16 ***
R&gt; Residuals       90 198402    2204                    
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p><strong>Task 13:</strong> What question are we asking with the above line of code? What is the answer? Also, why did we wrap <code>Time</code> in <code>as.factor()</code>?</p>
</blockquote>
<p>It is also possible to look at what the interaction effect between grouping variables (i.e. in this case the effect of time on diet—does the effect of time depend on which diet we are looking at?), and not just within the individual grouping variables. To do this we replace the <code>+</code> in our formula with <code>*</code>:</p>
<pre class="r"><code>summary(aov(weight ~ Diet * as.factor(Time), data = filter(chicks, Time %in% c(4, 21))))</code></pre>
<pre><code>R&gt;                      Df Sum Sq Mean Sq F value   Pr(&gt;F)    
R&gt; Diet                  3  40914   13638   6.968 0.000298 ***
R&gt; as.factor(Time)       1 582221  582221 297.472  &lt; 2e-16 ***
R&gt; Diet:as.factor(Time)  3  25530    8510   4.348 0.006684 ** 
R&gt; Residuals            86 168322    1957                     
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p><strong>Task 14:</strong> How do these results differ from the previous set?</p>
</blockquote>
<p>One may also run a post-hoc Tukey test on these results the same as for a single factor ANOVA:</p>
<pre class="r"><code>TukeyHSD(aov(weight ~ Diet * as.factor(Time), data = filter(chicks, Time %in% c(20, 21))))</code></pre>
<pre><code>R&gt;   Tukey multiple comparisons of means
R&gt;     95% family-wise confidence level
R&gt; 
R&gt; Fit: aov(formula = weight ~ Diet * as.factor(Time), data = filter(chicks, Time %in% c(20, 21)))
R&gt; 
R&gt; $Diet
R&gt;          diff        lwr       upr     p adj
R&gt; 2-1  36.18030  -9.301330  81.66194 0.1663037
R&gt; 3-1  90.63030  45.148670 136.11194 0.0000075
R&gt; 4-1  62.25253  15.223937 109.28111 0.0045092
R&gt; 3-2  54.45000   3.696023 105.20398 0.0305957
R&gt; 4-2  26.07222 -26.072532  78.21698 0.5586643
R&gt; 4-3 -28.37778 -80.522532  23.76698 0.4863940
R&gt; 
R&gt; $`as.factor(Time)`
R&gt;           diff       lwr      upr     p adj
R&gt; 21-20 8.088223 -17.44017 33.61661 0.5303164
R&gt; 
R&gt; $`Diet:as.factor(Time)`
R&gt;                 diff        lwr        upr     p adj
R&gt; 2:20-1:20  35.188235  -40.67378 111.050253 0.8347209
R&gt; 3:20-1:20  88.488235   12.62622 164.350253 0.0111136
R&gt; 4:20-1:20  63.477124  -14.99365 141.947897 0.2035951
R&gt; 1:21-1:20   7.338235  -58.96573  73.642198 0.9999703
R&gt; 2:21-1:20  44.288235  -31.57378 120.150253 0.6116081
R&gt; 3:21-1:20  99.888235   24.02622 175.750253 0.0023872
R&gt; 4:21-1:20  68.143791  -10.32698 146.614563 0.1371181
R&gt; 3:20-2:20  53.300000  -31.82987 138.429869 0.5234263
R&gt; 4:20-2:20  28.288889  -59.17374 115.751515 0.9723470
R&gt; 1:21-2:20 -27.850000 -104.58503  48.885027 0.9486212
R&gt; 2:21-2:20   9.100000  -76.02987  94.229869 0.9999766
R&gt; 3:21-2:20  64.700000  -20.42987 149.829869 0.2732059
R&gt; 4:21-2:20  32.955556  -54.50707 120.418182 0.9377007
R&gt; 4:20-3:20 -25.011111 -112.47374  62.451515 0.9862822
R&gt; 1:21-3:20 -81.150000 -157.88503  -4.414973 0.0305283
R&gt; 2:21-3:20 -44.200000 -129.32987  40.929869 0.7402877
R&gt; 3:21-3:20  11.400000  -73.72987  96.529869 0.9998919
R&gt; 4:21-3:20 -20.344444 -107.80707  67.118182 0.9960548
R&gt; 1:21-4:20 -56.138889 -135.45396  23.176184 0.3619622
R&gt; 2:21-4:20 -19.188889 -106.65152  68.273738 0.9972631
R&gt; 3:21-4:20  36.411111  -51.05152 123.873738 0.8984019
R&gt; 4:21-4:20   4.666667  -85.06809  94.401428 0.9999998
R&gt; 2:21-1:21  36.950000  -39.78503 113.685027 0.8067041
R&gt; 3:21-1:21  92.550000   15.81497 169.285027 0.0075185
R&gt; 4:21-1:21  60.805556  -18.50952 140.120628 0.2629945
R&gt; 3:21-2:21  55.600000  -29.52987 140.729869 0.4679025
R&gt; 4:21-2:21  23.855556  -63.60707 111.318182 0.9896157
R&gt; 4:21-3:21 -31.744444 -119.20707  55.718182 0.9486128</code></pre>
<blockquote>
<p><strong>Task 15:</strong> Yikes! That’s a massive amount of results. What does all of this mean, and why is it so verbose?</p>
</blockquote>
<!--- #### About interaction terms --->
<!-- AJS to insert stuff here -->
<blockquote>
<p><strong>Summary:</strong> To summarise <em>t</em>-tests, single-factor (1-way) and multifactor (2- or 3-way, etc.) ANOVAs:</p>
<ol style="list-style-type: decimal">
<li><p>A <em>t</em>-test is applied to situations where one wants to compare the means of only <strong>two</strong> groups of a response variable within <strong>one categorical independent variable</strong> (we say a factor with two levels).</p></li>
<li><p>A 1-way ANOVA also looks at the means of a response variable belonging to <strong>one categorical independent variable</strong>, but the categorical response variable has <strong>more than two</strong> levels in it.</p></li>
<li><p>Following on from there, a 2-way ANOVA compares the means of response variables belonging to all the levels within <strong>two categorical independent variables</strong> (e.g. Factor 1 might have three levels, and Factor 2 five levels). In the simplest formulaton, it does so by looking at the <strong>main effects</strong>, which is the group differences between the three levels of Factor 1 and disregarding the contribution due to the group membership to Factor 2, and also the group differences amongst the levels of Factor 2 but disregarding the group membership of Factor 1. In addition to looking at the main effects, a 2-way ANOVA can also consider the <strong>interaction</strong> (or combined effect) of Factors 1 and 2 in influencing the means.</p></li>
</ol>
</blockquote>
</div>
<div id="examples" class="section level3">
<h3>Examples</h3>
<div id="snakes" class="section level4">
<h4>Snakes!</h4>
<p>These data could be analysed by a two-way ANOVA without replication, or a repeated measures ANOVA. Here I will analyse it by using a two-way ANOVA without replication.</p>
<p>Place and Abramson (2008) placed diamondback rattlesnakes (<em>Crotalus atrox</em>) in a “rattlebox,” a box with a lid that would slide open and shut every 5 minutes. At first, the snake would rattle its tail each time the box opened. After a while, the snake would become habituated to the box opening and stop rattling its tail. They counted the number of box openings until a snake stopped rattling; fewer box openings means the snake was more quickly habituated. They repeated this experiment on each snake on four successive days, which is treated as an influential variable here. Place and Abramson (2008) used 10 snakes, but some of them never became habituated; to simplify this example, data from the six snakes that did become habituated on each day are used.</p>
<p>First, we read in the data, making sure to convert the column named <code>day</code> to a factor. Why? Because ANOVAs work with factor independent variables, while <code>day</code> as it is encoded by default is in fact a continuous variable.</p>
<pre class="r"><code>snakes &lt;- read_csv(&quot;../../../../static/data/snakes.csv&quot;)
snakes$day = as.factor(snakes$day)</code></pre>
<p>The first thing we do is to create some summaries of the data. Refer to the summary statistics Chapter.</p>
<pre class="r"><code>snakes.summary &lt;- snakes %&gt;% 
  group_by(day, snake) %&gt;% 
  summarise(mean_openings = mean(openings),
            sd_openings = sd(openings)) %&gt;% 
  ungroup()
snakes.summary</code></pre>
<pre><code>R&gt; # A tibble: 24 × 4
R&gt;    day   snake mean_openings sd_openings
R&gt;    &lt;fct&gt; &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;
R&gt;  1 1     D1               85          NA
R&gt;  2 1     D11              40          NA
R&gt;  3 1     D12              65          NA
R&gt;  4 1     D3              107          NA
R&gt;  5 1     D5               61          NA
R&gt;  6 1     D8               22          NA
R&gt;  7 2     D1               58          NA
R&gt;  8 2     D11              45          NA
R&gt;  9 2     D12              27          NA
R&gt; 10 2     D3               51          NA
R&gt; # … with 14 more rows</code></pre>
<blockquote>
<p><strong>Task 16:</strong> Something seems… off. What’s going on here? Please explain this outcome.</p>
</blockquote>
<p>To fix this problem, let us ignore the grouping by both <code>snake</code> and <code>day</code>.</p>
<pre class="r"><code>snakes.summary &lt;- snakes %&gt;% 
  group_by(day) %&gt;% 
  summarise(mean_openings = mean(openings),
            sd_openings = sd(openings)) %&gt;% 
  ungroup()
snakes.summary</code></pre>
<pre><code>R&gt; # A tibble: 4 × 3
R&gt;   day   mean_openings sd_openings
R&gt;   &lt;fct&gt;         &lt;dbl&gt;       &lt;dbl&gt;
R&gt; 1 1              63.3        30.5
R&gt; 2 2              47          12.2
R&gt; 3 3              34.5        26.0
R&gt; 4 4              25.3        18.1</code></pre>
<pre class="r"><code>library(Rmisc)
snakes.summary2 &lt;- summarySE(data = snakes, measurevar = &quot;openings&quot;, groupvars = c(&quot;day&quot;))</code></pre>
<p>Now we turn to some visual data summaries.</p>
<pre class="r"><code>ggplot(data = snakes, aes(x = day, y = openings)) +
  geom_segment(data = snakes.summary2, aes(x = day, xend = day, y = openings - ci, yend = openings + ci, colour = day),
              size = 2.0, linetype = &quot;solid&quot;, show.legend = F) +
  geom_boxplot(aes(fill = day), alpha = 0.6, show.legend = F) + 
  geom_jitter(width = 0.05)</code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/anova-plot5-1.png" width="70%" /></p>
<p>What are our null hypotheses?</p>
<ol style="list-style-type: decimal">
<li>H0: There is no difference between snakes with respect to the number of openings at which they habituate.</li>
<li>H0: There is no difference between days in terms of the number of openings at which the snakes habituate.</li>
</ol>
<p>Fit the ANOVA model to test these hypotheses:</p>
<pre class="r"><code>snakes.aov &lt;- aov(openings ~ day + snake, data = snakes)
summary(snakes.aov)</code></pre>
<pre><code>R&gt;             Df Sum Sq Mean Sq F value Pr(&gt;F)  
R&gt; day          3   4878  1625.9   3.320 0.0487 *
R&gt; snake        5   3042   608.4   1.242 0.3382  
R&gt; Residuals   15   7346   489.7                 
R&gt; ---
R&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Now we need to test of the assumptions hold true (i.e. erros are normally distributed and heteroscedastic). Also, where are the differences?</p>
<pre class="r"><code>par(mfrow = c(2, 2))
# Checking assumptions...
# make a histogram of the residuals;
# they must be normal
snakes.res &lt;- residuals(snakes.aov)
hist(snakes.res, col = &quot;red&quot;)

# make a plot of residuals and the fitted values;
# # they must be normal and homoscedastic
plot(fitted(snakes.aov), residuals(snakes.aov), col = &quot;red&quot;)

snakes.tukey &lt;- TukeyHSD(snakes.aov, which = &quot;day&quot;, conf.level = 0.90)
plot(snakes.tukey, las = 1, col = &quot;red&quot;)</code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/anova-plot6-1.png" width="70%" /></p>
</div>
</div>
</div>
<div id="alternatives-to-anova" class="section level2">
<h2>Alternatives to ANOVA</h2>
<p>In the first main section of this chapter we learned how to test hypotheses based on the comparisons of means between sets of data when we were able to meet our two base assumptions. These parametric tests are preferred over non-parametric tests because they are more robust. However, when we simply aren’t able to meet these assumptions we must not despair. Non-parametric tests are still useful. In this chapter we will learn how to run non-parametric tests for two sample and multiple sample datasets. To start, let’s load our libraries and <code>chicks</code> data if we have not already.</p>
<pre class="r"><code># First activate libraries
library(tidyverse)
library(ggpubr)

# Then load data
chicks &lt;- as_tibble(ChickWeight)</code></pre>
<p>With our libraries and data loaded, let’s find a day in which at least one of our assumptions are violated.</p>
<pre class="r"><code># Then check for failing assumptions
chicks %&gt;% 
  filter(Time == 0) %&gt;% 
  group_by(Diet) %&gt;% 
  summarise(norm_wt = as.numeric(shapiro.test(weight)[2]),
            var_wt = var(weight))</code></pre>
<pre><code>R&gt;       norm_wt   var_wt
R&gt; 1 0.000221918 1.282041</code></pre>
<div id="wilcox-rank-sum-test" class="section level3">
<h3>Wilcox rank sum test</h3>
<p>The non-parametric version of a <em>t</em>-test is a Wilcox rank sum test. To perform this test in R we may again use <code>compare_means()</code> and specify the test we want:</p>
<pre class="r"><code>compare_means(weight ~ Diet, data = filter(chicks, Time == 0, Diet %in% c(1, 2)), method = &quot;wilcox.test&quot;)</code></pre>
<pre><code>R&gt; # A tibble: 1 × 8
R&gt;   .y.    group1 group2     p p.adj p.format p.signif method  
R&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   
R&gt; 1 weight 1      2      0.235  0.23 0.23     ns       Wilcoxon</code></pre>
<p>What do our results show?</p>
</div>
<div id="kruskall-wallis-rank-sum-test" class="section level3">
<h3>Kruskall-Wallis rank sum test</h3>
<div id="single-factor-1" class="section level4">
<h4>Single factor</h4>
<p>The non-parametric version of an ANOVA is a Kruskall-Wallis rank sum test. As you may have by now surmised, this may be done with <code>compare_means()</code> as seen below:</p>
<pre class="r"><code>compare_means(weight ~ Diet, data = filter(chicks, Time == 0), method = &quot;kruskal.test&quot;)</code></pre>
<pre><code>R&gt; # A tibble: 1 × 6
R&gt;   .y.        p p.adj p.format p.signif method        
R&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;         
R&gt; 1 weight 0.475  0.48 0.48     ns       Kruskal-Wallis</code></pre>
<p>As with the ANOVA, this first step with the Kruskall-Wallis test is not the last. We must again run a post-hoc test on our results. This time we will need to use <code>pgirmess::kruskalmc()</code>, which means we will need to load a new library.</p>
<pre class="r"><code>library(pgirmess)

kruskalmc(weight ~ Diet, data = filter(chicks, Time == 0))</code></pre>
<pre><code>R&gt; Multiple comparison test after Kruskal-Wallis 
R&gt; p.value: 0.05 
R&gt; Comparisons
R&gt;     obs.dif critical.dif difference
R&gt; 1-2    6.95     14.89506      FALSE
R&gt; 1-3    6.90     14.89506      FALSE
R&gt; 1-4    4.15     14.89506      FALSE
R&gt; 2-3    0.05     17.19933      FALSE
R&gt; 2-4    2.80     17.19933      FALSE
R&gt; 3-4    2.75     17.19933      FALSE</code></pre>
<p>Let’s consult the help file for <code>kruskalmc()</code> to understand what this print-out means.</p>
</div>
<div id="multiple-factors-1" class="section level4">
<h4>Multiple factors</h4>
<p>The water becomes murky quickly when one wants to perform multiple factor non-parametric comparison of means tests. To that end, we will not cover the few existing methods here. Rather, one should avoid the necessity for these types of tests when designing an experiment.</p>
</div>
</div>
<div id="the-sa-time-data" class="section level3">
<h3>The SA time data</h3>
<pre class="r"><code>sa_time &lt;- as_tibble(read_csv(&quot;../../../../static/data/SA_time.csv&quot;, col_types = list(col_double(), col_double(), col_double())))
sa_time_long &lt;- sa_time %&gt;% 
  gather(key = &quot;term&quot;, value = &quot;minutes&quot;) %&gt;% 
  filter(minutes &lt; 300) %&gt;% 
  mutate(term = as.factor(term))

my_comparisons &lt;- list( c(&quot;now&quot;, &quot;now_now&quot;), c(&quot;now_now&quot;, &quot;just_now&quot;), c(&quot;now&quot;, &quot;just_now&quot;) )

ggboxplot(sa_time_long, x = &quot;term&quot;, y = &quot;minutes&quot;,
          color = &quot;term&quot;, palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;),
          add = &quot;jitter&quot;, shape = &quot;term&quot;)</code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/anova-plot7-1.png" width="70%" /></p>
<pre class="r"><code>ggviolin(sa_time_long, x = &quot;term&quot;, y = &quot;minutes&quot;, fill = &quot;term&quot;,
         palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;),
         add = &quot;boxplot&quot;, add.params = list(fill = &quot;white&quot;)) +
  stat_compare_means(comparisons = my_comparisons, label = &quot;p.signif&quot;) + # Add significance levels
  stat_compare_means(label.y = 50)                                      # Add global the p-value </code></pre>
<p><img src="/collection/biostats/chapters/07-anova_files/figure-html/anova-plot7-2.png" width="70%" /></p>
</div>
</div>

      </section>
      <footer class="post-footer">
        <div class="post-pagination dt w-100 mt4 mb2">
  
  
    <a class="prev dtc pr2 tl v-top fw6"
    href="/collection/biostats/chapters/06-t_tests/">&larr; 5. Inferences about one or two populations</a>
  
  
  
    <a class="next dtc pl2 tr v-top fw6"
    href="/collection/biostats/chapters/08-regressions/">7. Simple linear regressions &rarr;</a>
  
</div>

      </footer>
    </article>
    
  </section>
</main>

<aside class="page-sidebar" role="complementary">
                         
 











  <img src="/collection/featured-sidebar.jpg" class="db ma0">

                         
 



<div class="flex items-start sticky ph4 pb4 flex-row">
  <div class="w-two-thirds w-50-l ph0">
    <h2 class="mv3 f5 fw7 ttu tracked">
      <a class="no-underline dim" href="/collection/">Outline</a></h2>
    <nav id="SectionTableOfContents" aria-label="SectionTableOfContents">
        <ul>
        
          
          
          
          <details  class="">
            <summary class="" hugo-nav="/collection/intro_r/"><a href="/collection/intro_r/">BCB744 (Intro R)</a></summary>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/02-rstudio/"><a href="/collection/intro_r/chapters/02-rstudio/">1. RStudio and R</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/03-github/"><a href="/collection/intro_r/chapters/03-github/">2. GitHub</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/04-workflow/"><a href="/collection/intro_r/chapters/04-workflow/">3. An R workflow</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/05-graphics/"><a href="/collection/intro_r/chapters/05-graphics/">4. Graphics with ggplot2</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/06-faceting/"><a href="/collection/intro_r/chapters/06-faceting/">5. Faceting figures</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/07-brewing/"><a href="/collection/intro_r/chapters/07-brewing/">6. Brewing colours</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/08-mapping/"><a href="/collection/intro_r/chapters/08-mapping/">7. Mapping with ggplot2</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/09-mapping_style/"><a href="/collection/intro_r/chapters/09-mapping_style/">8. Mapping with style</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/10-mapping_openstreetmap/"><a href="/collection/intro_r/chapters/10-mapping_openstreetmap/">9. Mapping with OpenStreetMap</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/11-tidy/"><a href="/collection/intro_r/chapters/11-tidy/">10. Tidy data</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/12-tidier/"><a href="/collection/intro_r/chapters/12-tidier/">11. Tidier data</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/13-tidiest/"><a href="/collection/intro_r/chapters/13-tidiest/">12. Tidiest data</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/14-recap/"><a href="/collection/intro_r/chapters/14-recap/">13. Recap</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/15-functions/"><a href="/collection/intro_r/chapters/15-functions/">14. Functions by chapter</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/16-base_r/"><a href="/collection/intro_r/chapters/16-base_r/">15. Base R primer</a></li>
            
              
              <li class="" hugo-nav="/collection/intro_r/chapters/17-dates/"><a href="/collection/intro_r/chapters/17-dates/">16. Dates</a></li>
            
          </details>
          
          </li>
        
          
          
          
          <details open class="active">
            <summary class="active" hugo-nav="/collection/biostats/"><a href="/collection/biostats/">BCB744 (Biostats)</a></summary>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/02-data/"><a href="/collection/biostats/chapters/02-data/">1. Types of data</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/03-descriptive/"><a href="/collection/biostats/chapters/03-descriptive/">2. Central tendency and dispersion</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/04-graphics/"><a href="/collection/biostats/chapters/04-graphics/">3. Graphical data displays</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/06-t_tests/"><a href="/collection/biostats/chapters/06-t_tests/">5. Inferences about one or two populations</a></li>
            
              
              <li class="active" hugo-nav="/collection/biostats/chapters/07-anova/"><a href="/collection/biostats/chapters/07-anova/">6. Analysis of Variance (ANOVA)</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/08-regressions/"><a href="/collection/biostats/chapters/08-regressions/">7. Simple linear regressions</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/09-correlations/"><a href="/collection/biostats/chapters/09-correlations/">8. Correlation</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/10-confidence/"><a href="/collection/biostats/chapters/10-confidence/">9. Confidence intervals</a></li>
            
              
              <li class="" hugo-nav="/collection/biostats/chapters/11-transformations/"><a href="/collection/biostats/chapters/11-transformations/">10. Data transformations</a></li>
            
          </details>
          
          </li>
        
          
          
          
          <details  class="">
            <summary class="" hugo-nav="/collection/quantecol/"><a href="/collection/quantecol/">BCB743</a></summary>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/01-data/"><a href="/collection/quantecol/chapters/01-data/">1. Multivariate data</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/02-biodiversity/"><a href="/collection/quantecol/chapters/02-biodiversity/">2. Biodiversity</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/03-deep_dive/"><a href="/collection/quantecol/chapters/03-deep_dive/">3. Deep Dive into Gradients</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/04-env_dist/"><a href="/collection/quantecol/chapters/04-env_dist/">4. Environmental Distance</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/05-spp_dissimilarity/"><a href="/collection/quantecol/chapters/05-spp_dissimilarity/">5. Species Dissimilarities</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/06-correlations/"><a href="/collection/quantecol/chapters/06-correlations/">6. Correlations and Associations</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/08_pca/"><a href="/collection/quantecol/chapters/08_pca/">8a. Principal Component Analysis (PCA)</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/08-pca_sdg/"><a href="/collection/quantecol/chapters/08-pca_sdg/">8b. PCA of WHO SDGs</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/09-ca/"><a href="/collection/quantecol/chapters/09-ca/">9. Correspondence Analysis (CA)</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/10-pcoa/"><a href="/collection/quantecol/chapters/10-pcoa/">10. Principal Coordinate Analysis (PCoA)</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/11-nmds/"><a href="/collection/quantecol/chapters/11-nmds/">11a. non-Metric multidimensional scaling (nMDS)</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/11-nmds_diatoms/"><a href="/collection/quantecol/chapters/11-nmds_diatoms/">11b. nMDS of Mayombo&#39;s diatom data</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/12-constrained_ordination/"><a href="/collection/quantecol/chapters/12-constrained_ordination/">12. Constrained Ordination</a></li>
            
              
              <li class="" hugo-nav="/collection/quantecol/chapters/13-cluster_analysis/"><a href="/collection/quantecol/chapters/13-cluster_analysis/">13. Cluster analysis</a></li>
            
          </details>
          
          </li>
        
        </ul>
    </nav>
  </div>
  <details id="PageTableOfContents">
    <summary><h2 class="mv0 f5 fw7 ttu tracked dib">On this page<h2></summary>
    <div class="pl2 pr0 mh0">
    
    </div>
  </details>
  
</div>

</aside>

<footer class="site-footer pv4 bt b--transparent ph5" role="contentinfo">
  <nav class="db dt-l w-100">
    <p class="site-copyright f7 db dtc-l v-mid w-100 w-33-l tc tl-l pv2 pv0-l mv0 lh-copy">
      &copy; 2022 University of the Western Cape, Cape Town
      <span class="middot-divider"></span>
      Made with <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/hugo-apero/" rel="dct:source">Hugo Apéro</a></span>.
      <br />
      
Based on <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title"><a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/formspree/blogophonic-hugo" rel="dct:source">Blogophonic</a></span> by <a xmlns:cc="http://creativecommons.org/ns#" href="https://formspree.io" property="cc:attributionName" rel="cc:attributionURL">Formspree</a>.
    </p>
    
    <div class="site-social-links db dtc-l v-mid w-100 w-33-l tc pv2 pv0-l mv0">
      <div class="social-icon-links" aria-hidden="true">
  
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://github.com/ajsmit/" title="github" target="_blank" rel="noopener">
      <i class="fab fa-github fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="http://orcid.org/0000-0002-3799-6126" title="orcid" target="_blank" rel="noopener">
      <i class="ai ai-orcid fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://www.researchgate.net/profile/Albertus-Smit" title="researchgate" target="_blank" rel="noopener">
      <i class="ai ai-researchgate fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://uwc.academia.edu/AlbertusSmit" title="academia" target="_blank" rel="noopener">
      <i class="ai ai-academia fa-lg fa-fw"></i>
    </a>
  
    
    
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://scholar.google.co.za/citations?user=ATsBBKoAAAAJ&amp;hl=en" title="google-scholar" target="_blank" rel="noopener">
      <i class="ai ai-google-scholar fa-lg fa-fw"></i>
    </a>
  
    
    
    
      
    
    
    
    
    
      
    
    <a class="link dib h1 w1 ml0 mr2 f6 o-90 glow" href="https://www.instagram.com/ajsmit/" title="instagram" target="_blank" rel="noopener">
      <i class="fab fa-instagram fa-lg fa-fw"></i>
    </a>
  
</div>

    </div>
    
    <div class="site-links f6 db dtc-l v-mid w-100 w-67-l tc tr-l pv2 pv0-l mv0">
      
      <a class="dib pv1 ph2 link" href="/license/" title="License">License</a>
      
      <a class="dib pv1 ph2 link" href="/contact/" title="Contact form">Contact</a>
      
      <a class="dib pv1 ph2 link" href="/contributors/" title="Contributors">Contributors</a>
      
    </div>
  </nav>
  
    <script>

    var i, text, code, codes = document.getElementsByTagName('code');
    for (let i = 0; i < codes.length;) {
      code = codes[i];
      if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
        text = code.textContent;
        if (/^\$[^$]/.test(text) && /[^$]\$$/.test(text)) {
          text = text.replace(/^\$/, '\\(').replace(/\$$/, '\\)');
          code.textContent = text;
        }
        if (/^\\\((.|\s)+\\\)$/.test(text) ||
            /^\\\[(.|\s)+\\\]$/.test(text) ||
            /^\$(.|\s)+\$$/.test(text) ||
            /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
          code.outerHTML = code.innerHTML;  
          continue;
        }
      }
      i++;
    }
</script>

  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css" integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js" integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



    
  
  
</footer>

      </div>
    </body>
</html>
